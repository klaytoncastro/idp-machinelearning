{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b42c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import IsolationForest, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o Dataset\n",
    "url = 'https://raw.githubusercontent.com/klaytoncastro/idp-machinelearning/refs/heads/main/airquality/AirQualityUCI.csv'\n",
    "df = pd.read_csv(url, delimiter = ';', decimal = ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a estrutura de dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo as colunas Date e Time para DateTime\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H.%M.%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc934a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas originais Date e Time\n",
    "df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8de465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb082b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as correlações entre as variáveis ​​preditoras e a variável alvo\n",
    "correlations = df.corr()['CO(GT)'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5907f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos um padrão estranho, onde -200 aparece como valor mínimo para cada uma das variáveis.\n",
    "# Por isso, vamos contar valores -200 em cada coluna e avaliar se isso é frequente ou eventual.\n",
    "print(\"Contagem de valores -200 em cada coluna:\")\n",
    "for column in df.columns:\n",
    "    count_negative_200 = (df[column] == -200).sum()\n",
    "    print(f\"{column}: {count_negative_200}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De fato, são valores anômalos. Vamos substituir -200 por NaN (NULL)\n",
    "df.replace(-200, np.nan, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando quantidade de missing values por coluna\n",
    "missing_values = df.isna().sum().div(df.shape[0]).to_frame().sort_values(by=0, ascending=False)\n",
    "missing_values.plot(kind='bar', figsize=(10, 5))\n",
    "plt.title('Porcentagem de valores ausentes por coluna')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decidimos a descartar a coluna NMHC(GT), mais 80% de valores ausentes. Imputar a mediana pode apresentar padrões lineares artificiais.\n",
    "df.drop(columns=['NMHC(GT)'], inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova coluna para agregar os valores e gerando um gráfico de barras dos total de valores ausentes por registro único\n",
    "df['missing_values'] = df.isnull().any(axis=1)\n",
    "df.groupby('missing_values').size().plot(kind='bar')\n",
    "plt.title('Número de valores ausentes por observação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a778e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dadf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 1: se descartarmos as demais colunas ou registros com valores nulos, perderemos muita capacidade de previsão do modelo.\n",
    "# Poderiamos preencher os valores NaN com a mediana da coluna, mas os padrões lineares gerados seriam de fato artificiais.\n",
    "# Dessa forma, vamos seguir com a Hipótese 2.\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().any():\n",
    "        df[column].fillna(df[column].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 2: Como ainda teremos em torno de 7000 observações na amostra após remover os dados ausentes, decidimos removê-los para assegurar maior fidelidade.\n",
    "df = df.dropna()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As distribuições parecem melhores agora. Vamos exibir a nova matriz de correlação para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, vmin = -1)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos excluir a coluna intermediária 'missing_values' e a coluna 'DateTime'\n",
    "df.drop(columns=['DateTime'], inplace=True)\n",
    "#df.drop(columns=['missing_values'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0425e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos manter as demais variáveis de baixa correlação por enquanto.\n",
    "df.drop(columns=['T'], inplace=True)\n",
    "df.drop(columns=['RH'], inplace=True)\n",
    "df.drop(columns=['AH'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as correlações entre as variáveis ​​preditoras e a variável alvo\n",
    "correlations = df.corr()['CO(GT)'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d73221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando as variáveis para treinar o modelo.\n",
    "X = df.drop('CO(GT)', axis=1)\n",
    "y = df['CO(GT)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eeba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar com o ExtraTrees\n",
    "#model = ExtraTreesRegressor(random_state=7, n_estimators=67, max_features='sqrt', max_depth=100, min_samples_split=13, min_samples_leaf=1, bootstrap = False)\n",
    "#model = ExtraTreesRegressor(random_state=42, n_estimators=350, max_features='sqrt', max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "model = ExtraTreesRegressor();\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aaa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7428a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R² Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de valores previstos x valores atuais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=y_test, y=y_pred, color='blue', label='Valores Previstos')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='-', label='Ideal Line')\n",
    "plt.xlabel('Valores reais')\n",
    "plt.ylabel('Valores Previstos')\n",
    "plt.title('Valores previstos x Valores reais')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
