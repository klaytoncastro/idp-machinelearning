# -*- coding: utf-8 -*-
"""LIMIAR_winequality-ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WpRaBUZN0NJhhPlGo1311WpXRLJ8FSzI
"""

import pandas as pd

url = 'https://raw.githubusercontent.com/klaytoncastro/idp-machinelearning/main/decision-tree/winequality-merged.csv'
arquivo = pd.read_csv(url)
arquivo.head()

arquivo['color'] = arquivo['color'].replace('red', 0)
arquivo['color'] = arquivo['color'].replace('white', 1)

import numpy as np
arquivo['worst'] = np.where(arquivo['quality'] >= 7, 0, 1)

arquivo = arquivo.drop(['quality'], axis=1)

#arquivo = arquivo.drop(['color', 'quality'], axis=1)

#arquivo = arquivo.drop(['alcohol'], axis=1)

#arquivo = arquivo.drop(['free sulfur dioxide'], axis=1)

#arquivo = arquivo.drop(['density'], axis=1)

#arquivo = arquivo.drop(['alcohol', free sulfur dioxide', total sulfur dioxide'], axis=1)

arquivo.head()

import seaborn as sns
import matplotlib.pyplot as plt

# Calcular a matriz de correlação para as colunas numéricas do DataFrame
corr = arquivo.select_dtypes('number').corr()

# Personalizar a paleta de cores (opcional)
custom_palette = sns.color_palette("RdBu_r", n_colors=50)

# Plotar o mapa de calor usando o Seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap=custom_palette, fmt=".2f")
plt.title('Mapa de Calor da Matriz de Correlação')
plt.show()

# Calcular a matriz de correlação
correlation_matrix = arquivo.corr()

# Selecionar as correlações com a variável alvo ('quality')
correlation_with_target = correlation_matrix['worst']

# Excluir a correlação da variável alvo consigo mesma
correlation_with_target = correlation_with_target.drop('worst')

# Exibir os valores de correlação e nomes das variáveis preditoras
#print("Correlação com a variável alvo (worst):\n")
#print(correlation_with_target)

# Ordenar os valores de correlação em ordem decrescente
correlation_with_target_sorted = correlation_with_target.sort_values(ascending=False)

# Exibir os valores de correlação e nomes das variáveis preditoras ordenados
print("Correlação com a variável alvo (worst) - Ordenado:\n")
print(correlation_with_target_sorted)

# Converter a coluna 'worst' para o tipo de dados desejado (por exemplo, int)
arquivo['worst'] = arquivo['worst'].astype(int)

# Verificar o tipo de dados da coluna 'worst' após a conversão
print(arquivo['worst'].dtype)

# Informações gerais sobre o dataset
print(arquivo.info())

# Descrição estatística das variáveis numéricas
print(arquivo.describe())

print(arquivo['worst'].value_counts())

# Exibir o percentual de cada classe
print(arquivo['worst'].value_counts(normalize=True) * 100)

import matplotlib.pyplot as plt
arquivo.hist(figsize=(20, 15), bins=20)
plt.show()

arquivo.boxplot(figsize=(20, 10), rot=90)
plt.show()

# Check if 'color column exists in the DataFrame
if 'color' in arquivo.columns:
    print("Column 'color' exists in the DataFrame.")
    # Replace 'red' with 0 and 'white' with 1
    arquivo['color'] = arquivo['color'].replace('red', 0)
    arquivo['color'] = arquivo['color'].replace('white', 1)
else:
    print("Column 'color' does not exist in the DataFrame.")

# Display the first few rows of the DataFrame
print(arquivo.head())

import numpy as np
arquivo['worst'] = np.where(arquivo['quality'] >= 7, 0, 1)

arquivo = arquivo.drop('alcohol', axis = 1)
arquivo = arquivo.drop('density', axis = 1)
arquivo = arquivo.drop('free sulfur dioxide', axis = 1)

#arquivo = arquivo.drop('color', axis = 1)
#arquivo = arquivo.drop('quality', axis = 1)


#arquivo = arquivo.drop('citric acid', axis = 1)

#arquivo = arquivo.drop('pH', axis = 1)
#arquivo = arquivo.drop('sulphates', axis = 1)

#arquivo = arquivo.drop(['free sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'color', 'quality'], axis=1)
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'residual sugar'
Q1 = arquivo['residual sugar'].quantile(0.25)
Q3 = arquivo['residual sugar'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers residual sugar
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'residual sugar	'
arquivo = arquivo[(arquivo['residual sugar'] >= lim_inf) & (arquivo['residual sugar'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers volatile acidity
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'fixed acidity'
Q1 = arquivo['fixed acidity'].quantile(0.25)
Q3 = arquivo['fixed acidity'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers fixed acidity
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'fixed acidity'
arquivo = arquivo[(arquivo['fixed acidity'] >= lim_inf) & (arquivo['fixed acidity'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers fixed acidity
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'volatile acidity'
Q1 = arquivo['volatile acidity'].quantile(0.25)
Q3 = arquivo['volatile acidity'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers volatile acidity
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'volatile acidity'
arquivo = arquivo[(arquivo['volatile acidity'] >= lim_inf) & (arquivo['volatile acidity'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers volatile acidity
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'chlorides'
Q1 = arquivo['chlorides'].quantile(0.25)
Q3 = arquivo['chlorides'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers chlorides
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'chlorides'
arquivo = arquivo[(arquivo['chlorides'] >= lim_inf) & (arquivo['chlorides'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers chlorides
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'total sulfur dioxide'
Q1 = arquivo['total sulfur dioxide'].quantile(0.25)
Q3 = arquivo['total sulfur dioxide'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers na coluna 'total sulfur dioxide'
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'alcohol'
arquivo = arquivo[(arquivo['total sulfur dioxide'] >= lim_inf) & (arquivo['total sulfur dioxide'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers para a coluna 'total sulfur dioxide'
arquivo.head()

# Importar Pandas
import pandas as pd

# Calcular o Q1 (primeiro quartil) e Q3 (terceiro quartil) para a coluna 'free sulfur dioxide'
Q1 = arquivo['free sulfur dioxide'].quantile(0.25)
Q3 = arquivo['free sulfur dioxide'].quantile(0.75)

# Calcular o intervalo interquartil (IQR)
IQR = Q3 - Q1

# Definir limites inferior e superior para identificar outliers na coluna 'free sulfur dioxide'
lim_inf = Q1 - 1.5 * IQR
lim_sup = Q3 + 1.5 * IQR

# Remover outliers das colunas, exceto 'alcohol'
arquivo = arquivo[(arquivo['free sulfur dioxide'] >= lim_inf) & (arquivo['free sulfur dioxide'] <= lim_sup)]

# Exibir as primeiras linhas do DataFrame sem outliers para a coluna 'free sulfur dioxide'
arquivo.head()

arquivo_no_outliers = arquivo_no_outliers.drop('quality', axis = 1)
arquivo_no_outliers.head()

y = arquivo['worst']
X = arquivo.drop('worst',axis = 1)

#y = arquivo_no_outliers['worst']
#X = arquivo_no_outliers.drop('worst', axis = 1)

from sklearn.model_selection import train_test_split

# Assuming x is your feature set and y is the target variable
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)

from sklearn.ensemble import ExtraTreesClassifier
modelo = ExtraTreesClassifier()
modelo.fit(x_train, y_train)

y_pred = modelo.predict(x_test)

from sklearn.ensemble import ExtraTreesClassifier
modelo = ExtraTreesClassifier(n_estimators=50, max_depth=20, min_samples_leaf=1, min_samples_split=2, max_features="sqrt", class_weight="balanced", random_state=42) #Hiperparam
modelo.fit(x_train, y_train)

y_pred = modelo.predict(x_test)

from sklearn.ensemble import ExtraTreesClassifier

# Definir o modelo ExtraTreesClassifier com balanceamento de classe
modelo = ExtraTreesClassifier(class_weight='balanced')

# Treinar o modelo com os dados de treinamento
modelo.fit(x_train, y_train)

# Fazer previsões com o modelo balanceado
y_pred = modelo.predict(x_test)

# Definir os pesos das classes manualmente
class_weights = {0: 0.33, 1: 0.67}  # Por exemplo, atribuindo mais peso à classe 1

# Definir o modelo ExtraTreesClassifier com pesos de classe personalizados
modelo = ExtraTreesClassifier(class_weight=class_weights)

# Treinar o modelo com os dados de treinamento
modelo.fit(x_train, y_train)

# Fazer previsões com o modelo com pesos de classe personalizados
y_pred = modelo.predict(x_test)

from sklearn.ensemble import ExtraTreesClassifier

class_weights = {0: 0.5, 1: 0.5}  # Por exemplo, atribuindo mais peso à classe 1

modelo = ExtraTreesClassifier(n_estimators=50, max_depth=18, min_samples_leaf=1, min_samples_split=2, max_features="sqrt", random_state=42) #Hiperparam
modelo.fit(x_train, y_train)

y_pred = modelo.predict(x_test)

from imblearn.under_sampling import RandomUnderSampler

# Criar o objeto RandomUnderSampler
under_sampler = RandomUnderSampler()

# Aplicar a subamostragem aos dados de treinamento
x_train_resampled, y_train_resampled = under_sampler.fit_resample(x_train, y_train)

# Treinar o modelo com os dados de treinamento subamostrados
modelo_subamostragem = ExtraTreesClassifier()
modelo_subamostragem.fit(x_train_resampled, y_train_resampled)

# Fazer previsões com o modelo treinado
y_pred_subamostragem = modelo_subamostragem.predict(x_test)

resultado = modelo.score(x_test, y_test)
print ("Acurácia:", resultado)

# Adicionando a verificação da Precisão, Recall e F1-Score
from sklearn.metrics import precision_score, recall_score, f1_score

# Fazendo previsões no conjunto de teste
y_pred = modelo.predict(x_test)

# Calculando as métricas
precisao = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Precisão:", precisao)
print("Recall:", recall)
print("F1-score:", f1)

from sklearn.metrics import confusion_matrix, classification_report

"""
Calculando e exibindo a matriz de confusão. A orientação padrão é a seguinte:
[0,0]: Verdadeiros Negativos (VN) - Previsões corretamente identificadas como negativas.
[0,1]: Falsos Positivos (FP) - Previsões incorretamente identificadas como positivas.
[1,0]: Falsos Negativos (FN) - Previsões incorretamente identificadas como negativas.
[1,1]: Verdadeiros Positivos (VP) - Previsões corretamente identificadas como positivas.
"""

conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusão:")
print(conf_matrix)

"""
Calculando e exibindo as métricas de classificação.
Se algumas classes têm muito mais amostras do que outras, isso pode influenciar o desempenho e confiabilidade do modelo.

O "support" refere-se à quantidade de ocorrências da classe específica no conjunto de dados, sendo útil para verificar desbalanceamentos.
A "macro avg" calcula a média aritmética das métricas (precisão, recall, F1-score) para cada classe, sem considerar o número de instâncias em cada classe (support).
A "weighted avg" calcula a média ponderada das métricas para cada classe, considerando o número de instâncias em cada classe (support).
"""
print("Relatório de Classsificação:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Prever as probabilidades para os dados de teste.
# Note que estamos interessados nas probabilidades da classe positiva (1), então usamos [:, 1].
y_probs = modelo.predict_proba(x_test)[:, 1]

# Calcular FPR, TPR, e limiares
fpr, tpr, thresholds = roc_curve(y_test, y_probs)

# Calcular a AUC
roc_auc = auc(fpr, tpr)

# Plotar a curva ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

from joblib import dump

# Salvar o modelo em um arquivo .pkl
dump(modelo, 'modelo.pkl')

from google.colab import files
files.download('modelo.pkl')

import sklearn
print(sklearn.__version__)

# Selecionar amostras onde a variável worst é igual a 1 (vinho ruim)
ruins = arquivo.query('worst == 1')

# Selecionar amostras onde a variável worst é igual a 0 (vinho bom)
bons = arquivo.query('worst == 0')

bons.head()