{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw_82AA87nfF",
        "outputId": "0519bcad-c98c-4628-882a-6aa6bb16309b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Você começa.\n",
            "Sua jogada (0-8): 4\n",
            "\n",
            "Você jogou:\n",
            " | | \n",
            "-----\n",
            " |X| \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "\n",
            "Você jogou:\n",
            "O| | \n",
            "-----\n",
            " |X| \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Sua jogada (0-8): 5\n",
            "\n",
            "Você jogou:\n",
            "O| | \n",
            "-----\n",
            " |X|X\n",
            "-----\n",
            " | | \n",
            "-----\n",
            "\n",
            "Você jogou:\n",
            "O|O| \n",
            "-----\n",
            " |X|X\n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Sua jogada (0-8): 3\n",
            "\n",
            "Você jogou:\n",
            "O|O| \n",
            "-----\n",
            "X|X|X\n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Você venceu!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Parâmetros do Q-learning\n",
        "alpha = 0.5  # Taxa de aprendizado\n",
        "gamma = 0.9  # Fator de desconto\n",
        "epsilon = 0.1  # Probabilidade de exploração inicial\n",
        "decay_rate = 0.99  # Taxa de decaimento de epsilon\n",
        "q_table = {}  # A tabela Q será inicializada conforme os estados aparecem\n",
        "\n",
        "# Funções auxiliares para o jogo da velha\n",
        "def initialize_board():\n",
        "    return [' '] * 9\n",
        "\n",
        "def print_board(board):\n",
        "    for row in [board[i:i+3] for i in range(0, 9, 3)]:\n",
        "        print('|'.join(row))\n",
        "        print(\"-\" * 5)\n",
        "\n",
        "def is_winner(board, player):\n",
        "    winning_combinations = [(0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
        "                            (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
        "                            (0, 4, 8), (2, 4, 6)]\n",
        "    return any(board[a] == board[b] == board[c] == player for a, b, c in winning_combinations)\n",
        "\n",
        "def is_draw(board):\n",
        "    return ' ' not in board\n",
        "\n",
        "def available_actions(board):\n",
        "    return [i for i in range(9) if board[i] == ' ']\n",
        "\n",
        "def next_state(board, action, player):\n",
        "    new_board = board[:]\n",
        "    new_board[action] = player\n",
        "    return new_board\n",
        "\n",
        "# Função que escolhe a próxima ação do agente\n",
        "def choose_action(state, epsilon):\n",
        "    actions = available_actions(state)\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        return random.choice(actions)\n",
        "    else:\n",
        "        q_values = [q_table.get((tuple(state), a), 0) for a in actions]\n",
        "        return actions[np.argmax(q_values)]\n",
        "\n",
        "# Função que atualiza a tabela Q\n",
        "def update_q_table(state, action, reward, next_state, epsilon):\n",
        "    actions_next = available_actions(next_state)\n",
        "    next_max = max([q_table.get((tuple(next_state), a), 0) for a in actions_next], default=0)\n",
        "    q_table[(tuple(state), action)] = q_table.get((tuple(state), action), 0) + alpha * (reward + gamma * next_max - q_table.get((tuple(state), action), 0))\n",
        "\n",
        "# Função para jogar uma partida completa com escolha aleatória de quem começa\n",
        "def play_against_agent_random():\n",
        "    board = initialize_board()\n",
        "\n",
        "    # Sorteio para decidir quem começa\n",
        "    first_player = random.choice(['Você', 'Agente'])\n",
        "    print(f\"{first_player} começa.\")\n",
        "\n",
        "    if first_player == 'Você':\n",
        "        # Você começa como X\n",
        "        play_turn(board, 'X', 'Você', 'Agente')\n",
        "    else:\n",
        "        # O agente começa como X\n",
        "        play_turn(board, 'O', 'Agente', 'Você')\n",
        "\n",
        "def play_turn(board, player, current_player, opponent):\n",
        "    state = board[:]\n",
        "\n",
        "    while True:\n",
        "        if current_player == 'Você':\n",
        "            # Jogador humano joga\n",
        "            while True:\n",
        "                try:\n",
        "                    player_action = int(input(\"Sua jogada (0-8): \"))\n",
        "                    if player_action in available_actions(state):\n",
        "                        next_board = next_state(state, player_action, player)\n",
        "                        break\n",
        "                    else:\n",
        "                        print(\"Movimento inválido. Tente novamente.\")\n",
        "                except ValueError:\n",
        "                    print(\"Por favor, insira um número válido.\")\n",
        "\n",
        "            print(\"\\nVocê jogou:\")\n",
        "            print_board(next_board)\n",
        "\n",
        "            if is_winner(next_board, player):\n",
        "                print(\"Você venceu!\")\n",
        "                return\n",
        "            elif is_draw(next_board):\n",
        "                print(\"Empate!\")\n",
        "                return\n",
        "        else:\n",
        "            # Agente joga\n",
        "            action = choose_action(state, 0)  # Epsilon = 0 para jogar com a política aprendida\n",
        "            next_board = next_state(state, action, player)\n",
        "            print(f\"\\n{opponent} jogou:\")\n",
        "            print_board(next_board)\n",
        "\n",
        "            if is_winner(next_board, player):\n",
        "                print(f\"{opponent} venceu!\")\n",
        "                return\n",
        "            elif is_draw(next_board):\n",
        "                print(\"Empate!\")\n",
        "                return\n",
        "\n",
        "        # Alterna os jogadores\n",
        "        state = next_board[:]\n",
        "        if current_player == 'Você':\n",
        "            current_player, opponent = opponent, current_player\n",
        "            player = 'O' if player == 'X' else 'X'  # Alterna entre X e O\n",
        "        else:\n",
        "            current_player, opponent = opponent, current_player\n",
        "            player = 'O' if player == 'X' else 'X'\n",
        "\n",
        "# Função para treinar o agente sem interação (simulação)\n",
        "def play_game(epsilon):\n",
        "    board = initialize_board()\n",
        "    state = board[:]\n",
        "\n",
        "    while True:\n",
        "        # Jogador X (agente) joga\n",
        "        action = choose_action(state, epsilon)\n",
        "        next_board = next_state(state, action, 'X')\n",
        "\n",
        "        if is_winner(next_board, 'X'):\n",
        "            update_q_table(state, action, 1, next_board, epsilon)  # Vitória do X\n",
        "            break\n",
        "        elif is_draw(next_board):\n",
        "            update_q_table(state, action, 0, next_board, epsilon)  # Empate\n",
        "            break\n",
        "        else:\n",
        "            update_q_table(state, action, 0, next_board, epsilon)  # Jogo continua\n",
        "\n",
        "        # Oponente joga (jogador O - aleatório)\n",
        "        opponent_action = random.choice(available_actions(next_board))\n",
        "        next_board = next_state(next_board, opponent_action, 'O')\n",
        "\n",
        "        if is_winner(next_board, 'O'):\n",
        "            update_q_table(state, action, -1, next_board, epsilon)  # Derrota de X\n",
        "            break\n",
        "        elif is_draw(next_board):\n",
        "            update_q_table(state, action, 0, next_board, epsilon)  # Empate\n",
        "            break\n",
        "\n",
        "        # Passa para o próximo estado\n",
        "        state = next_board[:]\n",
        "\n",
        "# Treinamento do agente\n",
        "def train_agent(num_games):\n",
        "    global epsilon\n",
        "    for i in range(num_games):\n",
        "        play_game(epsilon)\n",
        "        epsilon *= decay_rate  # Decaimento de epsilon para reduzir a exploração\n",
        "\n",
        "# Treinando o agente\n",
        "train_agent(10000)  # Treina o agente com 10.000 partidas\n",
        "\n",
        "# Agora você pode jogar contra o agente com chance aleatória de começar\n",
        "play_against_agent_random()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
